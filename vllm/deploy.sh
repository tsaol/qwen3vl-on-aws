#!/bin/bash
set -e

echo "========================================"
echo "Qwen3-VL on AWS - è‡ªåŠ¨éƒ¨ç½²è„šæœ¬"
echo "========================================"

# æ£€æŸ¥æ˜¯å¦åœ¨ GPU å®ä¾‹ä¸Š
if ! command -v nvidia-smi &> /dev/null; then
    echo "âŒ é”™è¯¯: æœªæ£€æµ‹åˆ° NVIDIA GPU"
    echo "è¯·åœ¨ GPU å®ä¾‹ä¸Šè¿è¡Œæ­¤è„šæœ¬ï¼ˆå¦‚ G5, P3, P4 ç³»åˆ—ï¼‰"
    exit 1
fi

echo "âœ… æ£€æµ‹åˆ° GPU:"
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader

# æ£€æŸ¥ Python ç‰ˆæœ¬
if ! command -v python3.10 &> /dev/null; then
    echo "âš ï¸  æœªæ‰¾åˆ° Python 3.10ï¼Œå°è¯•å®‰è£…..."
    sudo apt-get update
    sudo apt-get install -y python3.10 python3.10-venv
fi

echo "âœ… Python ç‰ˆæœ¬: $(python3.10 --version)"

# å®‰è£… uvï¼ˆå¦‚æœæœªå®‰è£…ï¼‰
if ! command -v uv &> /dev/null; then
    echo "ğŸ“¦ å®‰è£… uv åŒ…ç®¡ç†å™¨..."
    curl -LsSf https://astral.sh/uv/install.sh | sh
    export PATH="$HOME/.local/bin:$PATH"
fi

echo "âœ… uv ç‰ˆæœ¬: $(uv --version)"

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "ğŸ”§ åˆ›å»º Python è™šæ‹Ÿç¯å¢ƒ..."
uv venv --python 3.10 --seed

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo "ğŸ”§ æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ..."
source .venv/bin/activate

# å®‰è£… vLLM
echo "ğŸ“¦ å®‰è£… vLLMï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."
uv pip install vllm --torch-backend=auto

# éªŒè¯å®‰è£…
echo "ğŸ” éªŒè¯å®‰è£…..."
python -c "import vllm; import torch; print(f'vLLM ç‰ˆæœ¬: {vllm.__version__}'); print(f'PyTorch ç‰ˆæœ¬: {torch.__version__}'); print(f'CUDA å¯ç”¨: {torch.cuda.is_available()}')"

echo ""
echo "========================================"
echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "========================================"
echo ""
echo "å¯åŠ¨ vLLM æœåŠ¡ï¼š"
echo "  source .venv/bin/activate"
echo "  vllm serve Qwen/Qwen3-VL-8B-Instruct --port 8000 --max-model-len 1024 --gpu-memory-utilization 0.95"
echo ""
echo "æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼š"
echo "  bash start_server.sh"
echo ""
